{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpxkFfPbb+fxqR3u3LyYe7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajendra5811/Python-Project-for-Data-Engineering/blob/main/simple_ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsWkNneDA-zM",
        "outputId": "6505eaf3-4bf3-4d86-d6a4-f1ba01101e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "Transformed Data\n",
            "Empty DataFrame\n",
            "Columns: [name, height, weight]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "print('hello')\n",
        "import numpy as np\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from datetime import datetime\n",
        "\n",
        "log_file = \"log_file.txt\"\n",
        "target_file = \"transformed_data.csv\"\n",
        "\n",
        "def extract_from_csv(file_to_process):\n",
        "    dataframe = pd.read_csv(file_to_process)\n",
        "    return dataframe\n",
        "def extract_from_json(file_to_process):\n",
        "    dataframe = pd.read_json(file_to_process, lines=True)\n",
        "    return dataframe\n",
        "\n",
        "def extract_from_xml(file_to_process):\n",
        "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n",
        "    tree = ET.parse(file_to_process)\n",
        "    root = tree.getroot()\n",
        "    for person in root:\n",
        "        name = person.find(\"name\").text\n",
        "        height = float(person.find(\"height\").text)\n",
        "        weight = float(person.find(\"weight\").text)\n",
        "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True)\n",
        "    return dataframe\n",
        "def extract():\n",
        "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data\n",
        "\n",
        "    # process all csv files, except the target file\n",
        "    for csvfile in glob.glob(\"*.csv\"):\n",
        "        if csvfile != target_file:  # check if the file is not the target file\n",
        "            extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True)\n",
        "\n",
        "    # process all json files\n",
        "    for jsonfile in glob.glob(\"*.json\"):\n",
        "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True)\n",
        "\n",
        "    # process all xml files\n",
        "    for xmlfile in glob.glob(\"*.xml\"):\n",
        "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index=True)\n",
        "\n",
        "    return extracted_data\n",
        "\n",
        "def transform(data):\n",
        "    '''Convert inches to meters and round off to two decimals\n",
        "    1 inch is 0.0254 meters '''\n",
        "    data['height'] = round(data.height * 0.0254,2)\n",
        "\n",
        "    '''Convert pounds to kilograms and round off to two decimals\n",
        "    1 pound is 0.45359237 kilograms '''\n",
        "    data['weight'] = round(data.weight * 0.45359237,2)\n",
        "\n",
        "    return data\n",
        "\n",
        "def load_data(target_file, transformed_data):\n",
        "    transformed_data.to_csv(target_file)\n",
        "\n",
        "def log_progress(message):\n",
        "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n",
        "    now = datetime.now() # get current timestamp\n",
        "    timestamp = now.strftime(timestamp_format)\n",
        "    with open(log_file,\"a\") as f:\n",
        "        f.write(timestamp + ',' + message + '\\n')\n",
        "\n",
        "# Log the initialization of the ETL process\n",
        "log_progress(\"ETL Job Started\")\n",
        "\n",
        "# Log the beginning of the Extraction process\n",
        "log_progress(\"Extract phase Started\")\n",
        "extracted_data = extract()\n",
        "\n",
        "# Log the completion of the Extraction process\n",
        "log_progress(\"Extract phase Ended\")\n",
        "\n",
        "# Log the beginning of the Transformation process\n",
        "log_progress(\"Transform phase Started\")\n",
        "transformed_data = transform(extracted_data)\n",
        "print(\"Transformed Data\")\n",
        "print(transformed_data)\n",
        "\n",
        "# Log the completion of the Transformation process\n",
        "log_progress(\"Transform phase Ended\")\n",
        "\n",
        "# Log the beginning of the Loading process\n",
        "log_progress(\"Load phase Started\")\n",
        "load_data(target_file,transformed_data)\n",
        "\n",
        "# Log the completion of the Loading process\n",
        "log_progress(\"Load phase Ended\")\n",
        "\n",
        "# Log the completion of the ETL process\n",
        "log_progress(\"ETL Job Ended\")\n"
      ]
    }
  ]
}